# BÃ¡o CÃ¡o Lab 06: Nháº­n Dáº¡ng Thá»±c Thá»ƒ TÃªn (NER) vá»›i RNN (lab6_rnn_for_ner.ipynb)

## ğŸ“‹ Má»¥c Lá»¥c
1. [Giáº£i ThÃ­ch CÃ¡c BÆ°á»›c Triá»ƒn Khai](#1-giáº£i-thÃ­ch-cÃ¡c-bÆ°á»›c-triá»ƒn-khai)
2. [HÆ°á»›ng Dáº«n Thá»±c Thi MÃ£](#2-hÆ°á»›ng-dáº«n-thá»±c-thi-mÃ£)
3. [PhÃ¢n TÃ­ch Káº¿t Quáº£](#3-phÃ¢n-tÃ­ch-káº¿t-quáº£)
4. [ThÃ¡ch Thá»©c vÃ  Giáº£i PhÃ¡p](#4-thÃ¡ch-thá»©c-vÃ -giáº£i-phÃ¡p)
5. [HÆ°á»›ng PhÃ¡t Triá»ƒn](#5-hÆ°á»›ng-phÃ¡t-triá»ƒn)

---

## 1. Giáº£i ThÃ­ch CÃ¡c BÆ°á»›c Triá»ƒn Khai

### Task 1: Táº£i vÃ  Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u
- **Má»¥c Ä‘Ã­ch**: Táº£i bá»™ dá»¯ liá»‡u chuáº©n CoNLL-2003 vÃ  chuáº©n bá»‹ tá»« Ä‘iá»ƒn.
- **BÆ°á»›c thá»±c hiá»‡n**:
  - Sá»­ dá»¥ng thÆ° viá»‡n `datasets` cá»§a Hugging Face Ä‘á»ƒ táº£i `conll2003`.
  - TrÃ­ch xuáº¥t cÃ¢u (tokens) vÃ  nhÃ£n (ner_tags).
  - Chuyá»ƒn Ä‘á»•i nhÃ£n tá»« dáº¡ng sá»‘ sang dáº¡ng chuá»—i (vÃ­ dá»¥: `0` -> `O`, `1` -> `B-PER`) Ä‘á»ƒ dá»… kiá»ƒm soÃ¡t.
  - XÃ¢y dá»±ng `word_to_ix` (Ã¡nh xáº¡ tá»« -> index) vÃ  `tag_to_ix` (Ã¡nh xáº¡ nhÃ£n -> index).
  - ThÃªm token Ä‘áº·c biá»‡t: `<PAD>` (Ä‘á»‡m), `<UNK>` (tá»« láº¡).

### Task 2: Táº¡o PyTorch Dataset vÃ  DataLoader
- **Má»¥c Ä‘Ã­ch**: ÄÃ³ng gÃ³i dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n theo batch.
- **BÆ°á»›c thá»±c hiá»‡n**:
  - Táº¡o class `NERDataset` káº¿ thá»«a `torch.utils.data.Dataset`.
  - Viáº¿t hÃ m `collate_fn` sá»­ dá»¥ng `pad_sequence` Ä‘á»ƒ Ä‘á»‡m cÃ¡c cÃ¢u vÃ  chuá»—i nhÃ£n vá» cÃ¹ng Ä‘á»™ dÃ i trong má»™t batch.
  - Tráº£ vá» thÃªm `lengths` (Ä‘á»™ dÃ i thá»±c cá»§a cÃ¢u) Ä‘á»ƒ sá»­ dá»¥ng cho cÆ¡ cháº¿ `pack_padded_sequence`.

### Task 3: XÃ¢y dá»±ng MÃ´ hÃ¬nh RNN
- **Má»¥c Ä‘Ã­ch**: XÃ¢y dá»±ng mÃ´ hÃ¬nh sequence labeling máº¡nh máº½ hÆ¡n POS Tagging.
- **Kiáº¿n trÃºc mÃ´ hÃ¬nh**:
  1. **Embedding Layer**: Chuyá»ƒn Ä‘á»•i index tá»« sang vector (dim=100).
  2. **Bi-LSTM Layer**: Sá»­ dá»¥ng **LSTM hai chiá»u** (Bidirectional LSTM) thay vÃ¬ RNN thÆ°á»ng. LSTM giÃºp giáº£i quyáº¿t váº¥n Ä‘á» vanishing gradient tá»‘t hÆ¡n vÃ  náº¯m báº¯t phá»¥ thuá»™c xa.
     - Hidden dim: 256.
     - Bidirectional: True (Output dim = 256 * 2 = 512).
  3. **Dropout**: Tá»· lá»‡ 0.3 Ä‘á»ƒ giáº£m overfitting.
  4. **Linear Layer**: Ãnh xáº¡ output cá»§a LSTM sang sá»‘ lÆ°á»£ng nhÃ£n NER.
- **Ká»¹ thuáº­t**: Sá»­ dá»¥ng `pack_padded_sequence` Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ­nh toÃ¡n, bá» qua cÃ¡c token padding.

### Task 4: Huáº¥n luyá»‡n MÃ´ hÃ¬nh
- **Cáº¥u hÃ¬nh**:
  - Optimizer: Adam (lr=0.001).
  - Loss function: CrossEntropyLoss (ignore_index=PAD_TAG).
  - Epochs: 10.
- **Quy trÃ¬nh**:
  - TÃ­nh toÃ¡n Loss vÃ  Accuracy trÃªn táº­p train sau má»—i epoch.
  - Accuracy Ä‘Æ°á»£c tÃ­nh báº±ng cÃ¡ch so sÃ¡nh nhÃ£n dá»± Ä‘oÃ¡n vÃ  nhÃ£n tháº­t, **bá» qua cÃ¡c vá»‹ trÃ­ padding**.

### Task 5: ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh
- **Má»¥c Ä‘Ã­ch**: Kiá»ƒm tra kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a trÃªn táº­p Validation vÃ  Test.
- **PhÆ°Æ¡ng phÃ¡p**:
  - Sá»­ dá»¥ng hÃ m `evaluate` Ä‘á»ƒ tÃ­nh Loss vÃ  Accuracy trÃªn táº­p Val/Test.
  - Äáº£m báº£o khÃ´ng tÃ­nh toÃ¡n gradient (`torch.no_grad()`) Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»›.
  - Viáº¿t hÃ m `predict_sentence` Ä‘á»ƒ dá»± Ä‘oÃ¡n thá»±c thá»ƒ cho cÃ¢u nháº­p vÃ o báº¥t ká»³.

---

## 2. HÆ°á»›ng Dáº«n Thá»±c Thi MÃ£

### 2.1 YÃªu Cáº§u Há»‡ Thá»‘ng
```bash
pip install torch datasets numpy
```

### 2.2 Cáº¥u TrÃºc ThÆ° Má»¥c
```
 notebook/
    Lab06/
       lab6_rnn_for_ner.ipynb
```

### 2.3 CÃ¡ch Cháº¡y
1. **Má»Ÿ Jupyter Notebook**:
   ```bash
   jupyter notebook notebook/Lab06/lab6_rnn_for_ner.ipynb
   ```
2. **Cháº¡y tuáº§n tá»± cÃ¡c cell**:
   - Cell 1-2: Import thÆ° viá»‡n vÃ  setup seed.
   - Cell 3-6: Táº£i dá»¯ liá»‡u CoNLL-2003 vÃ  xÃ¢y dá»±ng vocab.
   - Cell 7-9: Táº¡o Dataset vÃ  DataLoader.
   - Cell 10-11: Äá»‹nh nghÄ©a mÃ´ hÃ¬nh Bi-LSTM.
   - Cell 12-13: Huáº¥n luyá»‡n mÃ´ hÃ¬nh (10 epochs).
   - Cell 14-15: ÄÃ¡nh giÃ¡ trÃªn táº­p Validation vÃ  Test.
   - Cell 16-17: Dá»± Ä‘oÃ¡n cÃ¢u má»›i.

---

## 3. PhÃ¢n TÃ­ch Káº¿t Quáº£

### 3.1 QuÃ¡ TrÃ¬nh Huáº¥n Luyá»‡n Chi Tiáº¿t
DÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ chi tiáº¿t cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n qua 10 epochs:

| Epoch | Train Loss | Train Accuracy | Nháº­n XÃ©t |
|:-----:|:----------:|:--------------:|:---------|
| 1     | 0.819      | 82.22%         | Khá»Ÿi Ä‘áº§u tá»‘t, mÃ´ hÃ¬nh há»c nhanh cÃ¡c quy luáº­t cÆ¡ báº£n. |
| 2     | 0.521      | 86.07%         | Loss giáº£m máº¡nh, accuracy tÄƒng gáº§n 4%. |
| 3     | 0.399      | 88.46%         | |
| 4     | 0.316      | 90.67%         | VÆ°á»£t má»‘c 90% accuracy. |
| 5     | 0.260      | 92.21%         | |
| 6     | 0.219      | 93.36%         | |
| 7     | 0.186      | 94.39%         | |
| 8     | 0.161      | 95.04%         | Äáº¡t má»‘c 95% accuracy. |
| 9     | 0.140      | 95.68%         | |
| 10    | 0.121      | 96.21%         | Train loss ráº¥t tháº¥p, mÃ´ hÃ¬nh há»c ráº¥t tá»‘t trÃªn táº­p train. |

### 3.2 Káº¿t Quáº£ ÄÃ¡nh GiÃ¡
- **Validation Accuracy**: **94.45%** (Loss: 0.242)
- **Test Accuracy**: **92.60%** (Loss: 0.349)

### 3.3 Nháº­n XÃ©t

#### 1. Hiá»‡u Suáº¥t Tá»•ng Thá»ƒ
- **Äá»™ chÃ­nh xÃ¡c cao**: MÃ´ hÃ¬nh Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c **92.60%** trÃªn táº­p Test. ÄÃ¢y lÃ  káº¿t quáº£ ráº¥t áº¥n tÆ°á»£ng cho bÃ i toÃ¡n NER, Ä‘áº·c biá»‡t khi chá»‰ sá»­ dá»¥ng kiáº¿n trÃºc Bi-LSTM cÆ¡ báº£n mÃ  khÃ´ng cÃ³ CRF hay pre-trained embeddings phá»©c táº¡p (nhÆ° BERT).
- **Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a**: Sá»± chÃªnh lá»‡ch giá»¯a Train Acc (96.21%) vÃ  Test Acc (92.60%) lÃ  khoáº£ng 3.6%. Äiá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh cÃ³ hiá»‡n tÆ°á»£ng overfitting nháº¹ nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t trÃªn dá»¯ liá»‡u chÆ°a tá»«ng gáº·p.

#### 2. Vai TrÃ² Cá»§a Bi-LSTM
- Viá»‡c sá»­ dá»¥ng **LSTM hai chiá»u** lÃ  yáº¿u tá»‘ then chá»‘t. Trong NER, viá»‡c xÃ¡c Ä‘á»‹nh má»™t tá»« lÃ  thá»±c thá»ƒ hay khÃ´ng phá»¥ thuá»™c ráº¥t nhiá»u vÃ o ngá»¯ cáº£nh cáº£ hai phÃ­a.
- VÃ­ dá»¥: Trong cÃ¢u "Washington is a beautiful city", "Washington" lÃ  Ä‘á»‹a danh (LOC). NhÆ°ng trong "Washington announced a new policy", "Washington" cÃ³ thá»ƒ lÃ  tá»• chá»©c (ORG) hoáº·c ngÆ°á»i (PER). Bi-LSTM giÃºp mÃ´ hÃ¬nh nhÃ¬n tháº¥y tá»« "city" hoáº·c "announced" Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘Ãºng.

### 3.4 VÃ­ Dá»¥ Dá»± ÄoÃ¡n
CÃ¢u: *"VNU University is located in Hanoi"*
- **Dá»± Ä‘oÃ¡n**:
  - VNU: **B-ORG** (Tá»• chá»©c)
  - University: **I-ORG** (Tá»• chá»©c)
  - is: **O**
  - located: **O**
  - in: **O**
  - Hanoi: **O** (Dá»± Ä‘oÃ¡n sai, láº½ ra pháº£i lÃ  B-LOC)
- **PhÃ¢n tÃ­ch**:
  - MÃ´ hÃ¬nh nháº­n diá»‡n Ä‘Ãºng cá»¥m "VNU University" lÃ  tá»• chá»©c (ORG).
  - Tuy nhiÃªn, tá»« "Hanoi" bá»‹ dá»± Ä‘oÃ¡n nháº§m thÃ nh "O" (khÃ´ng pháº£i thá»±c thá»ƒ). Äiá»u nÃ y cÃ³ thá»ƒ do tá»« "Hanoi" Ã­t xuáº¥t hiá»‡n trong táº­p train (CoNLL-2003 chá»§ yáº¿u lÃ  dá»¯ liá»‡u tin tá»©c phÆ°Æ¡ng TÃ¢y) hoáº·c do mÃ´ hÃ¬nh chÆ°a Ä‘á»§ máº¡nh Ä‘á»ƒ báº¯t Ä‘Æ°á»£c ngá»¯ cáº£nh nÃ y. ÄÃ¢y lÃ  minh chá»©ng cho thÃ¡ch thá»©c vá» **OOV (Out-of-Vocabulary)** vÃ  **Domain Adaptation**.

---

## 4. ThÃ¡ch Thá»©c vÃ  Giáº£i PhÃ¡p

### 4.1 ThÃ¡ch Thá»©c
- **Dá»¯ liá»‡u máº¥t cÃ¢n báº±ng**: NhÃ£n `O` chiáº¿m Ä‘a sá»‘ Ã¡p Ä‘áº£o. Náº¿u khÃ´ng xá»­ lÃ½ tá»‘t, mÃ´ hÃ¬nh sáº½ cÃ³ xu hÆ°á»›ng dá»± Ä‘oÃ¡n má»i thá»© lÃ  `O` Ä‘á»ƒ Ä‘áº¡t accuracy cao (nhÆ°ng F1-score cho thá»±c thá»ƒ sáº½ ráº¥t tháº¥p).
- **Tá»« láº¡ (OOV)**: TÃªn riÃªng (nhÆ° "Hanoi", "VNU") thÆ°á»ng khÃ´ng cÃ³ trong tá»« Ä‘iá»ƒn huáº¥n luyá»‡n, dáº«n Ä‘áº¿n viá»‡c mÃ´ hÃ¬nh pháº£i dá»±a hoÃ n toÃ n vÃ o ngá»¯ cáº£nh hoáº·c gÃ¡n token `<UNK>`.
- **Overfitting**: Vá»›i mÃ´ hÃ¬nh máº¡nh nhÆ° LSTM vÃ  táº­p dá»¯ liá»‡u nhá»/trung bÃ¬nh, mÃ´ hÃ¬nh dá»… há»c thuá»™c lÃ²ng.

### 4.2 Giáº£i PhÃ¡p
- **Masking**: Sá»­ dá»¥ng `ignore_index` trong Loss function vÃ  masking khi tÃ­nh Accuracy Ä‘á»ƒ loáº¡i bá» áº£nh hÆ°á»Ÿng cá»§a padding, giÃºp Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hÆ¡n.
- **Dropout**: Sá»­ dá»¥ng Dropout vá»›i tá»· lá»‡ 0.3 Ä‘á»ƒ giáº£m thiá»ƒu overfitting.
- **Bi-LSTM**: Táº­n dá»¥ng ngá»¯ cáº£nh toÃ n cá»¥c Ä‘á»ƒ giáº£m bá»›t sá»± phá»¥ thuá»™c vÃ o viá»‡c tá»« Ä‘Ã³ cÃ³ trong tá»« Ä‘iá»ƒn hay khÃ´ng.

---

## 5. HÆ°á»›ng PhÃ¡t Triá»ƒn

### 5.1 Cáº£i Tiáº¿n MÃ´ HÃ¬nh
- **Bi-LSTM-CRF**: ThÃªm lá»›p **CRF (Conditional Random Fields)**. CRF cá»±c ká»³ há»¯u Ã­ch trong NER vÃ¬ nÃ³ há»c Ä‘Æ°á»£c cÃ¡c quy luáº­t chuyá»ƒn Ä‘á»•i nhÃ£n (vÃ­ dá»¥: `I-ORG` khÃ´ng bao giá» Ä‘i sau `B-PER`). Äiá»u nÃ y sáº½ giÃºp sá»­a cÃ¡c lá»—i dá»± Ä‘oÃ¡n vÃ´ lÃ½.
- **Pre-trained Embeddings**: Sá»­ dá»¥ng **GloVe** hoáº·c **FastText** Ä‘á»ƒ khá»Ÿi táº¡o embedding. FastText Ä‘áº·c biá»‡t tá»‘t cho NER vÃ¬ nÃ³ sá»­ dá»¥ng subword information, giÃºp xá»­ lÃ½ tá»‘t hÆ¡n cÃ¡c tá»« OOV vÃ  tÃªn riÃªng.
- **Character-level Embedding**: Káº¿t há»£p thÃªm CNN/LSTM á»Ÿ má»©c kÃ½ tá»± Ä‘á»ƒ mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c Ä‘iá»ƒm hÃ¬nh thÃ¡i (nhÆ° viáº¿t hoa, Ä‘uÃ´i "-tion", "-ing").

### 5.2 Transformer & LLMs
- Chuyá»ƒn sang sá»­ dá»¥ng **BERT** (Bidirectional Encoder Representations from Transformers). BERT Ä‘Ã£ Ä‘Æ°á»£c pre-train trÃªn lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ vÃ  hiá»ƒu ngá»¯ cáº£nh sÃ¢u sáº¯c hÆ¡n nhiá»u so vá»›i LSTM. Fine-tuning BERT trÃªn CoNLL-2003 thÆ°á»ng cho káº¿t quáº£ SOTA (>93-94% F1).

---
**Káº¿t luáº­n**: BÃ i thá»±c hÃ nh Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng há»‡ thá»‘ng NER sá»­ dá»¥ng Bi-LSTM vá»›i Ä‘á»™ chÃ­nh xÃ¡c kháº£ quan (~92.6% trÃªn táº­p Test). Máº·c dÃ¹ cÃ²n má»™t sá»‘ háº¡n cháº¿ vá»›i cÃ¡c tá»« hiáº¿m (nhÆ° vÃ­ dá»¥ "Hanoi"), nhÆ°ng Ä‘Ã¢y lÃ  ná»n táº£ng vá»¯ng cháº¯c Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c há»‡ thá»‘ng trÃ­ch xuáº¥t thÃ´ng tin phá»©c táº¡p hÆ¡n.
